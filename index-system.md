---
title:  关于沃德社会气象台-智能分析模块的系统设计建议
heading:  如何开发设计一套百度/微信/淘宝指数产品
date: 2020-02-27T06:14:24.971Z
categories: ["life"]
draft: true
tags: 
description: 
---

以上仅

不免有错误的地方，仅作为一个想法

难免有说的不对的地方，

我知道同事们在开发此模块的期间，肯定遇到了很多我没考虑到的技术难点。我仅以这两天的体验，提出的意见肯定有错误的地方，


关于百度指数，好搜指数，微指数，google趋势，淘宝指数，各种指数的架构设计猜想。



1.一定有一个公司维护的词库信息，可以随时动态增加和减少。

用户输入了词库里不存在的词，进行记录，然后由维护人员酌情添加。

防止危险，当一个试用用户大量无效词，这样也算一种攻击，会占用大量的计算器资源。


2. 采集信息的时间粒度准确性


3. 产品设计层面对用户良好的引导

为什么会出现如此问题

现状问题


对沃民智能分析产品的设计。

改进设计方案


热门词抽取：数量为，文本长度的25%，后期可酌情增加到50%。

redis

建议设计气象台相关的技术人员都深度体验一下这几个产品，试用的过程中请思考与我们有哪些不一样，不一样的地方为什么要如此设计，如果使用其他设计方案会有什么问题。

总之，多用多思考。



态势分析
输入：关键词、时间范围、数据源、评价（积极、中级、消极）
输出：不同来源在时间范围内每隔1小时的资讯数量折线图。不同来源的数据占比。

印象分析
输入：关键词、时间范围、数据源
输出：词云，与之相关的词，在时间段内的占比。

爆点分析：
输入：关键词、时间范围、数据源、评价（积极、中级、消极）
输出：印象（词云）在时间范围内的1小时折线图

评价分析
输入：关键词、时间范围、数据源
输出：时间段内评价数量，每一小时的评价数量。


用户分析
输入：关键词、时间范围、数据源、评价
输出：地区分布比例，男女比例

类别分析
输入：关键词、时间范围、数据源、评价
输出：类别占比（社会时政、健康医疗、投资理财、健康养生、娱乐明星）

节点分析
输入：关键词、评价
输出：新闻列表

数据建模

一条资讯

时间、词、数据源（一级分类/二级分类）、评价、类别， 新闻数量、权重

针对时间的处理：秒+计数器（最高10亿，可按需拆成词的计数器，小时/天），有覆盖数据的风险，但概率奇低。


hbase。按天存储。

词+时间（天）+数据源（一级分类/二级分类）、评价、类别， 新闻数量、权重

目前数据源30个，评价3个，类别6个，一个词在统计时间单位内最多产生540条信息。假设词库有100万，所有词在单个统计的时间单位内最多产生5.4亿条数据。

按天聚合统计，则一天最多5.4亿条统计信息。按照小时聚合统计，一天最多`5.4亿/h*24h=129.6`亿条统计信息。

为了平衡数据量和时间粒度，最近24小时内的数据按小时统计，数据量最多为129.6亿条，超过24小时的数据按天统计。一年最多5.4亿/天*365天=1971亿条数据。

时序数据库如DolphinDB、InfluxDB、OpenTSDB，天然适合解决类似统计信息的聚合需求。

百亿级别的数据量，使用单机64G内存，响应速度可优化到秒级别。超过百亿后需要使用集群方案。

目前开源的时序数据库系统，一般处理百亿级别的数据量没有什么问题，超过上、千亿以后基本要考虑收费方案了。若不选择收费方案，也可以通过技术手段，建立分表、把统计时间的粒度放粗、自建集群等方法来解决。







540

solr

新闻id，时间(小时),数据源/评价/类别，分词结果集（）



图数据库
热门词/推荐词
用户试用的时候
动态词维护
时间粒度：最低小时级别
分词 计数

